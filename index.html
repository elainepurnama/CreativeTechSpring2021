<!DOCTYPE html>
<html>
	<head>
		<title> EPGitHub </title>


	</head>
	<body>
		<h1>Creative Technology 3</h1>
		<body style="backround: white;">
		<h2>Week 1: On "Programming Design Systems" by Rune Madsen</h2>
		<h3>"...graphic designers have always used systems in their work. We use grid systems to balance our layouts and color circles to pick colors with proper distance to each other. History has shown us that systems can cure the fear of the blank canvas..." - </h3>
		<p>I particularly like that an example here is given as a way to connect graphic design to systems. I think most of time, the connection between graphic design and systems can be unclear, as some people might ask "What does graphic design, or making things look good, have to do with systems?". This quote gives a direct example of how systems are used in such a discipline. However, the part I like the most about this quote is the last sentence. I agree that without having some sort of system, it can be intimidating to start on a design when the canvas is blank. Without a system, I sometimes ask myself: Where do I start? What colour should I choose? It is interesting how even on a blank canvas, having a system, even mentally, will help with starting a design, and sometimes even gives us more freedom to try different things.</p>
		<br>
		<h3>"Rather than trying to establish some unified theory about why color behaves this way, Albers describes how students can repeat these experiments to experience it on their own."</h3>
		<p> I am quite fond of the way Albers allows experimentation for the sake of personal experience, rather than trying to establish a unified theory on color. Building upon what was talked about in the text, on the objectivity vs. subjectivity of the experience of colour, I think that it is important to note that there are psychological aspects to color theory that are "objective" and should be considered, however it is also important to allow the designer or user to experience color and color combinations themselves for a subjective point of view. Albers' way of teaching experiments for students to experience things on their own is important for the combination of an objective understanding of color theory and a subjective experience. </p>
		<br>
		<h2>Week 2: On Chapter 7 of "You Look Like a Thing and I Love You" by Janelle Shane</h2>
		<h3>"People who use AIs that have been trained on human-generated text need to expect that some bias will come along for the ride–and they need to plan what to do about it."</h3>
		<p>It seems to me that the idea that 'bias will come along for the ride' is an obvious fact and it is common practice for designers, developers and those who work with AI to be aware and prepare to deal with bias, or perhaps even try to prevent algorithmic bias, but I then wonder why bias is so often overlooked? Is there a way in which people who are working with algorithmic bias in AI can be be better prepared with identifying bias? If AI "COPY THE HUMANS", like mentioned in this chapter, then perhaps instead of only being prepared for bias and planning what to do about it, people can undergo some sort of bias identification training themselves first, to identify their own biases and re-educate themselves to remove these personal biases before working with AI, so that they have a better chance of not feeding AI with biased information through the capability of identifying biases more easily.</p>
		<br>
		<h3>"And this still leaves the question of how we decide which words–if any–should have gender distinctions."
		<p>I'm not sure how I feel about this. On one hand, I feel that perhaps no words should have gender distinctions. Perhaps if there are no words with gender distinctions, then the bias problem with words and their connection to gender might be solved. However, even if there are no words with gender distinctions, there might still be gender bias from text used in the internet. So on the other hand I feel like I recognize the problem is not within words that have gender distinctions, but how people perceive genders in general.</p> 
		<b3>
		<h3>"...we need people to make sure their "brilliant solution" isn't a head-slapper. And those people will need to be familliar with the ways Ais tend to succeed or go wrong. It's a bit like checking the work of a colleague–a very, very strange colleague."</h3>
		<p>What interests me here is the idea of looking at AI as colleagues (very, very strange ones), not machines or tools. It's interesting to look at AI as not just tools that we use but perhaps beings that need to be taught team values and how-tos, the same way we would a new, slightly lost and very strange colleague.</p>

	</body>
</html>