<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BmbxuPwQa2lc/FVzBcNJ7UAyJxM6wuqIj61tLrc4wSX0szH/Ev+nYRRuWlolflfl" crossorigin="anonymous">
        <link rel="preconnect" href="https://fonts.gstatic.com">
        <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@200;400&display=swap" rel="stylesheet">
        <title> EP Creative Tech III GitHub </title>
        <style>
            h1,h2,h3,h4 {
            font-family: 'Roboto Mono', monospace;
            font-weight: 400;
            color: #515151;
            }
            p {
            font-family: 'Roboto Mono', monospace;
            font-weight: 200;
            color: #515151;
            }
        </style>
    </head>
    <body>
        <body style="backround: white;">
            <div class="container-fluid text-left">
            <div class="row content">
            <div class="col-sm-2"></div>
            <div class="col-sm-8 sidenav">
                <h1 class="fnt">Creative Technology 3</h1>
                <h2>Week 1: On "Programming Design Systems" by Rune Madsen</h2>
                <h3>"...graphic designers have always used systems in their work. We use grid systems to balance our layouts and color circles to pick colors with proper distance to each other. History has shown us that systems can cure the fear of the blank canvas..." - </h3>
                <p>I particularly like that an example here is given as a way to connect graphic design to systems. I think most of time, the connection between graphic design and systems can be unclear, as some people might ask "What does graphic design, or making things look good, have to do with systems?". This quote gives a direct example of how systems are used in such a discipline. However, the part I like the most about this quote is the last sentence. I agree that without having some sort of system, it can be intimidating to start on a design when the canvas is blank. Without a system, I sometimes ask myself: Where do I start? What colour should I choose? It is interesting how even on a blank canvas, having a system, even mentally, will help with starting a design, and sometimes even gives us more freedom to try different things.</p>
                <br>
                <h3>"Rather than trying to establish some unified theory about why color behaves this way, Albers describes how students can repeat these experiments to experience it on their own."</h3>
                <p> I am quite fond of the way Albers allows experimentation for the sake of personal experience, rather than trying to establish a unified theory on color. Building upon what was talked about in the text, on the objectivity vs. subjectivity of the experience of colour, I think that it is important to note that there are psychological aspects to color theory that are "objective" and should be considered, however it is also important to allow the designer or user to experience color and color combinations themselves for a subjective point of view. Albers' way of teaching experiments for students to experience things on their own is important for the combination of an objective understanding of color theory and a subjective experience. </p>
                <br>
                <h2>Week 2: On Chapter 7 of "You Look Like a Thing and I Love You" by Janelle Shane</h2>
                <h3>"People who use AIs that have been trained on human-generated text need to expect that some bias will come along for the ride–and they need to plan what to do about it."</h3>
                <p>It seems to me that the idea that 'bias will come along for the ride' is an obvious fact and it is common practice for designers, developers and those who work with AI to be aware and prepare to deal with bias, or perhaps even try to prevent algorithmic bias, but I then wonder why bias is so often overlooked? Is there a way in which people who are working with algorithmic bias in AI can be be better prepared with identifying bias? If AI "COPY THE HUMANS", like mentioned in this chapter, then perhaps instead of only being prepared for bias and planning what to do about it, people can undergo some sort of bias identification training themselves first, to identify their own biases and re-educate themselves to remove these personal biases before working with AI, so that they have a better chance of not feeding AI with biased information through the capability of identifying biases more easily.</p>
                <br>
                <h3>"And this still leaves the question of how we decide which words–if any–should have gender distinctions."</h3>
                <p>I'm not sure how I feel about this. On one hand, I feel that perhaps no words should have gender distinctions. Perhaps if there are no words with gender distinctions, then the bias problem with words and their connection to gender might be solved. However, even if there are no words with gender distinctions, there might still be gender bias from text used in the internet. So on the other hand I feel like I recognize the problem is not within words that have gender distinctions, but how people perceive genders in general.</p>
                <br>
                <h3>"And those people will need to be familliar with the ways Ais tend to succeed or go wrong. It's a bit like checking the work of a colleague–a very, very strange colleague."</h3>
                <p>What interests me here is the idea of looking at AI as colleagues (very, very strange ones), not machines or tools. It's interesting to look at AI as not just tools that we use but perhaps beings that need to be taught team values and how-tos, the same way we would a new, slightly lost and very strange colleague. If we treat them as beings (colleagues) and not as tools, then maybe we'll be able to identify the biases that they learn through the data we feed them. </p>
                <br>
                <h2>Whispers to Alexa - A Rube Goldberg Machine</h2>
                <p>Group Members: Isabelle Chaligne, Tingyi Li, Elaine Purnama
                    <br><br>
                    For this three week assignment, we were asked to look at The Web as a Rube Goldberg Machine - a machine / system where the user initiates a single action, which triggers a chain of events. 
                    <br><br>
                    Our first thought was a poetry generator machine, using this kind of system: 
                    <br><br><img src="Images/whisperstoalexa_1.png" alt="Fig 1. Initial concept diagram"><br><br>
                    Due to time constraints, we had to modify our plan, and decided to play with what we could do instead. We finally decided on the concept of the telephone game, or Chinese Whispers, where information is transferred (and usually changed) from one person to another. 
                    <br><br>
                    This is the system we came up with:
                    <br><br><img src="Images/whisperstoalexa_2.png" alt="Fig 2. Final concept diagram"><br>
                    Final Video:
                    <br><br>
                    <iframe width="420" height="315"
                        src="https://www.youtube.com/embed/0rklfqZl6RY">
                    </iframe>
                    <br><br>
                    Given more time, we would have liked to add more parts to the system. We initially tried to use Musixmatch in the process between Twitter and Spotify, so that the tweet would trigger a song search in Musixmatch, which would save the first song listed in the search, and would then trigger another search in Spotify using the title of the saved song. We were unable to get this to work, so we removed it, but would like to add other applications as part of the system.
                </p>
                <br>
            </div>
            <div class="col-sm-2"></div>
    </body>
</html>
